{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install necessary requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "%pip install numpy h5py spacy pandas tqdm scikit-learn scipy matplotlib ipython --quiet\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup for the dataset\n",
    "\n",
    "The datasets can be downloaded from https://recsys.eb.dk/.\n",
    "\n",
    "1. Download the eb_nerd dataset locally on your computer.\n",
    "2. Create the following folder: `RecSysGroup27/ebnerd_data`.\n",
    "3. Extract the dataset into the `ebnerd_data` folder. \\\n",
    "The folder should contain the following datasets: \\\n",
    "`ebnerd_data/ebnerd_demo` \\\n",
    "`ebnerd_data/ebnerd_large` \\\n",
    "`ebnerd_data/ebnerd_small` \\\n",
    "`ebnerd_data/ebnerd_testset`\n",
    "\n",
    "Not all datasets are needed. ebnerd_large is only needed if you want to run on the large dataset and ebnerd_testset is only needed if you want to run on the test set. We recommend only using ebnerd_small and ebnerd_demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy model 'da_core_news_lg' is already installed.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "from NRMS import NRMS\n",
    "from NRMSExtended import NRMSExtended\n",
    "import spacy\n",
    "\n",
    "# Install danish language model if it is not already installed\n",
    "try:\n",
    "    nlp = spacy.load(\"da_core_news_lg\")\n",
    "    print(\"spaCy model 'da_core_news_lg' is already installed.\")\n",
    "except:\n",
    "    print(\"spaCy model 'da_core_news_lg' not found. Installing...\")\n",
    "    !python -m spacy download da_core_news_lg --quiet\n",
    "    nlp = spacy.load(\"da_core_news_lg\")\n",
    "\n",
    "from Training import train, testOnWholeDataset\n",
    "from Testing import runOnTestSet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameters. If you run into memory issues, turn batch_size and validation_batch_size down. You can turn down max_batches if you want to finish the training faster.\\\n",
    "You can change ebnerd_small to ebnerd_demo if you want the data loading to be faster. This may cause the training results to be worse.\\\n",
    "You can see if cuda is activated below. We recommend running with cuda activated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Check for available device\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "# Model parameters\n",
    "dropout = 0.2\n",
    "h = 16                              # Number of attention heads in multi-head self-attention\n",
    "\n",
    "# Train parameters\n",
    "dataset_name = 'ebnerd_small'   # Name of the dataset used for training and validating\n",
    "k = 4                           # Number of negative samples to pair with each positive sample\n",
    "batch_size = 64\n",
    "weight_decay = 0.0\n",
    "learning_rate = 1e-3\n",
    "history_size = 30               # Number of user history entries after truncation or padding\n",
    "max_title_size = 20             # Number of tokens in an article title after truncation or padding\n",
    "num_epochs = 100                # Not really used (takes too long to reach number of epochs)\n",
    "validate_every = 100            # How many train batches between validations\n",
    "validation_batch_size = 100     # The batch size for validation\n",
    "n_validation_batches = 100       # How many batches to run for each validation\n",
    "max_batches = 1000              # Turn this down if you want to end the training early\n",
    "\n",
    "save_model = False #Activate this if you want the best model to be saved during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the model is created. You can choose whether to use time embeddings or not.\n",
    "Please restart the kernel if you have already created a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m     model \u001b[38;5;241m=\u001b[39m NRMSExtended(nlp, h\u001b[38;5;241m=\u001b[39mh, dropout\u001b[38;5;241m=\u001b[39mdropout)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m----> 6\u001b[0m     model \u001b[38;5;241m=\u001b[39m NRMS(nlp, h\u001b[38;5;241m=\u001b[39mh, dropout\u001b[38;5;241m=\u001b[39mdropout)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n",
      "File \u001b[1;32mc:\\Users\\jensl\\Desktop\\RecSysGroup27\\NRMS.py:18\u001b[0m, in \u001b[0;36mNRMS.__init__\u001b[1;34m(self, nlp, h, dropout)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnlp \u001b[38;5;241m=\u001b[39m nlp\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnews_encoder \u001b[38;5;241m=\u001b[39m NewsEncoder(nlp\u001b[38;5;241m=\u001b[39mnlp, d_model_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model_out, h\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMHSA \u001b[38;5;241m=\u001b[39m MultiHeadedAttention(h\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh, d_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model_out, d_model_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model_out, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n",
      "File \u001b[1;32mc:\\Users\\jensl\\Desktop\\RecSysGroup27\\NewsEncoder.py:14\u001b[0m, in \u001b[0;36mNewsEncoder.__init__\u001b[1;34m(self, nlp, d_model_out, h, dropout)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh \u001b[38;5;241m=\u001b[39m h\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;241m=\u001b[39m dropout\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewsEmbedder \u001b[38;5;241m=\u001b[39m NewsEmbedder(nlp, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnlp \u001b[38;5;241m=\u001b[39m nlp\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMHSA \u001b[38;5;241m=\u001b[39m MultiHeadedAttention(h\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh, d_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m, d_model_out\u001b[38;5;241m=\u001b[39md_model_out, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n",
      "File \u001b[1;32mc:\\Users\\jensl\\Desktop\\RecSysGroup27\\NewsEmbedder.py:12\u001b[0m, in \u001b[0;36mNewsEmbedder.__init__\u001b[1;34m(self, nlp, dropout)\u001b[0m\n\u001b[0;32m     10\u001b[0m data\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;241m0.0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddingDimension)])\n\u001b[0;32m     11\u001b[0m vectors \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(data)\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mEmbedding(vectors\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], vectors\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], padding_idx\u001b[38;5;241m=\u001b[39mvectors\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m vectors\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(p\u001b[38;5;241m=\u001b[39mdropout)\n",
      "File \u001b[1;32mc:\\Users\\jensl\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:167\u001b[0m, in \u001b[0;36mEmbedding.__init__\u001b[1;34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight, _freeze, device, dtype)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_grad_by_freq \u001b[38;5;241m=\u001b[39m scale_grad_by_freq\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(\n\u001b[1;32m--> 167\u001b[0m         torch\u001b[38;5;241m.\u001b[39mempty((num_embeddings, embedding_dim), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs),\n\u001b[0;32m    168\u001b[0m         requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m _freeze,\n\u001b[0;32m    169\u001b[0m     )\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_parameters()\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with_time_embeddings = True\n",
    "\n",
    "if with_time_embeddings:\n",
    "    model = NRMSExtended(nlp, h=h, dropout=dropout).to(DEVICE)\n",
    "else:\n",
    "    model = NRMS(nlp, h=h, dropout=dropout).to(DEVICE)\n",
    "\n",
    "#Uncomment this line if you want to load a model from a saved file.\n",
    "#model.load_state_dict(torch.load('model_best.pth', map_location=DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell runs the training. Here, we train much less than we did for the results shown in the report. Turn up max_batches if you want more training.\n",
    "Data loading may take up to around 1 minute for ebnerd_small. Use ebnerd_demo as explained above to load faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train(\n\u001b[0;32m      2\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m      3\u001b[0m         dataset_name\u001b[38;5;241m=\u001b[39mdataset_name,\n\u001b[0;32m      4\u001b[0m         k\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m      5\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m      6\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[0;32m      7\u001b[0m         learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[0;32m      8\u001b[0m         history_size\u001b[38;5;241m=\u001b[39mhistory_size,\n\u001b[0;32m      9\u001b[0m         max_title_size\u001b[38;5;241m=\u001b[39mmax_title_size,\n\u001b[0;32m     10\u001b[0m         nlp\u001b[38;5;241m=\u001b[39mnlp,\n\u001b[0;32m     11\u001b[0m         save_model\u001b[38;5;241m=\u001b[39msave_model,\n\u001b[0;32m     12\u001b[0m         num_epochs\u001b[38;5;241m=\u001b[39mnum_epochs,\n\u001b[0;32m     13\u001b[0m         validate_every\u001b[38;5;241m=\u001b[39mvalidate_every,\n\u001b[0;32m     14\u001b[0m         validation_batch_size\u001b[38;5;241m=\u001b[39mvalidation_batch_size,\n\u001b[0;32m     15\u001b[0m         n_validation_batches\u001b[38;5;241m=\u001b[39mn_validation_batches,\n\u001b[0;32m     16\u001b[0m         max_batches\u001b[38;5;241m=\u001b[39mmax_batches,\n\u001b[0;32m     17\u001b[0m         with_time_embeddings\u001b[38;5;241m=\u001b[39mwith_time_embeddings\n\u001b[0;32m     18\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jensl\\Desktop\\RecSysGroup27\\Training.py:161\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dataset_name, k, batch_size, weight_decay, learning_rate, history_size, max_title_size, nlp, save_model, num_epochs, validate_every, validation_batch_size, n_validation_batches, max_batches, with_time_embeddings)\u001b[0m\n\u001b[0;32m    159\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    160\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m--> 161\u001b[0m outputs_np \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(batch_outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    162\u001b[0m targets_np \u001b[38;5;241m=\u001b[39m convertgtPositionsToVec(batch_gtpositions, k\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs_np:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(\n",
    "        model=model,\n",
    "        dataset_name=dataset_name,\n",
    "        k=k,\n",
    "        batch_size=batch_size,\n",
    "        weight_decay=weight_decay,\n",
    "        learning_rate=learning_rate,\n",
    "        history_size=history_size,\n",
    "        max_title_size=max_title_size,\n",
    "        nlp=nlp,\n",
    "        save_model=save_model,\n",
    "        num_epochs=num_epochs,\n",
    "        validate_every=validate_every,\n",
    "        validation_batch_size=validation_batch_size,\n",
    "        n_validation_batches=n_validation_batches,\n",
    "        max_batches=max_batches,\n",
    "        with_time_embeddings=with_time_embeddings,\n",
    "        plot_results=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can run the model on the whole validation dataset. We recommend running on ebnerd_demo or ebnerd_small. These have about 25000 and 250000 impressions respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load data:  3.4959352016448975\n",
      "Finished: 10000/25356\n",
      "Finished: 20000/25356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AUC: 100%|██████████████████████████████| 25356/25356 [00:12<00:00, 2038.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final AUC score on whole dataset:  0.5477819841980534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): #Test on whole validation set\n",
    "        final_auc = testOnWholeDataset(model, \"ebnerd_demo\", \"validation\", history_size, max_title_size, nlp, batch_size=validation_batch_size, with_time_embeddings=with_time_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can run on the entire test set and produce an predictions file. This takes a long time so we do not recommend doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load data:  2.648240327835083\n",
      "Finished: 10000/25356\n",
      "Finished: 20000/25356\n",
      "Saving file...\n"
     ]
    }
   ],
   "source": [
    "#Uncomment these lines if you want to run on the test set\n",
    "#with torch.no_grad():\n",
    "    #runOnTestSet(model, history_size, max_title_size, nlp, batch_size=validation_batch_size, with_time_embeddings=with_time_embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
